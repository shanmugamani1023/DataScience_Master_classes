{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3feeb444",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f062c03",
   "metadata": {},
   "source": [
    "# Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9607f680",
   "metadata": {},
   "source": [
    "# laso regression used for add a penaly term to the cost function so,the less important features will remove.\n",
    "penaly term-absolute sum of coefficients of features\n",
    "\n",
    "Normal Linear regression vs lasso:\n",
    "    linear regression dont do any feature selection \n",
    "    so,linear regression cant reduce overfitting\n",
    "    \n",
    "lasso vs ridge:\n",
    "    ridge -l2 regularization term\n",
    "    lasso -l1 regularization term\n",
    "    ridge -uses penalty term as squares of co efficient of features \n",
    "    lasso -uses absolute sum of coefficient of features.\n",
    "    \n",
    "    ridge -reduce features not exactly 0,but towards 0\n",
    "    lasso-reduce feature into 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7926207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "202e151d",
   "metadata": {},
   "source": [
    "# Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e2ed2d",
   "metadata": {},
   "source": [
    "# 1.feature selection\n",
    "# 2.by using feature selection we can get subset of features .so we can reduce the training time and prediction time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc2fa95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70a433b1",
   "metadata": {},
   "source": [
    "# Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bfaa11",
   "metadata": {},
   "source": [
    "# Interpreting the coefficients of lasso regression model is explain the coefficient of model.coeffcient of model explains strength and direction of independent  features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeb6c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3aaf7d4b",
   "metadata": {},
   "source": [
    "# Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the \n",
    "model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2460f9fc",
   "metadata": {},
   "source": [
    "# lambda -regularization strength,\n",
    "# increase lambda-more feature will reduce-it hard to fit the trainning data in the model-so high bias.\n",
    "# decrease lambda-feature selection will be low-overfitting may occur-so low bias but high variance.\n",
    "# so,choosing lambda regularization parameter is essential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1d1ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f18c2089",
   "metadata": {},
   "source": [
    "# Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b24832",
   "metadata": {},
   "source": [
    "# Lasso Regression is not suitable for non-linear regression problems due to its linear nature, there are alternative regression techniques specifically designed for such scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02018c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb7d7c2e",
   "metadata": {},
   "source": [
    "# Q6. What is the difference between Ridge Regression and Lasso Regression"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05c99a49",
   "metadata": {},
   "source": [
    "# Both ridge,lasso reduce overfitting by add the penalty term\n",
    "\n",
    "but ridge -uses l2 regularization as penalty,\n",
    "lasso -l1 regularization as penalty,\n",
    "\n",
    "l2 regularization:\n",
    "    squares  of coefficient of features\n",
    "    it will check multicollinearity(Multicollinearity is a statistical phenomenon that occurs when two or more independent variables in a regression model are highly correlated with each other)\n",
    "    it will reduce coefficients but not  exactly zero for mainatin stability in model \n",
    "\n",
    "l1 regularization:\n",
    "    absolute value of sum of coefficient of features\n",
    "    it will automatically check feature selection\n",
    "    it will reduce some coefficients by exactly zero for mainatin stability in model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f757626e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4b6b3b4",
   "metadata": {},
   "source": [
    "# 7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a46ab1",
   "metadata": {},
   "source": [
    "# yes ,not completely but for some extent it l try to reduce multicollinearity.\n",
    "lasso regression will try do features selection ,so if there is a multicollinearity it will choose one of the features and will build the model function.its a type of multicollinarity reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0880e19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3847add",
   "metadata": {},
   "source": [
    "# Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d36f1e",
   "metadata": {},
   "source": [
    "# 1.grid search cv\n",
    "# 2.random search cv\n",
    "# 3.cross valdation\n",
    "# 4.domain expertise\n",
    "# 5.automatic vallue detection by scikit-learn kind of libraries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2acba391",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412b6c8f",
   "metadata": {},
   "source": [
    "# Q1. What is Ridge Regression, and how does it differ from ordinary least squares regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e1ee1",
   "metadata": {},
   "source": [
    "### Ridge regression used for reduce overfitting in model by adding penalty term(called l2 regularization).so cost function will subtract with penalty term called multiplication of reqularization hyper parameter with squares of coefficient of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e79870",
   "metadata": {},
   "source": [
    "### The main diff b/w ridge and ols is multicollinearity handling ,ridge cant handle that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed38f5d",
   "metadata": {},
   "source": [
    "\n",
    "### multicollinarity means relationship b/w independent variable is positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b9980b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c34ef019",
   "metadata": {},
   "source": [
    "# Q2. What are the assumptions of Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af8ce98",
   "metadata": {},
   "source": [
    "1.linearity b/w independent and dependent variables\n",
    "2.Residual b/w one data point not have any relationship b/w other datapoint\n",
    "3.Residual value b/w one and another are same and residual will equally distributed.\n",
    "4.It will assume that there is a multicolinearity so need to check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70650458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb524db8",
   "metadata": {},
   "source": [
    "# Q3. How do you select the value of the tuning parameter (lambda) in Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be37454c",
   "metadata": {},
   "source": [
    "# 1.grid search cv -using grid search cv we can try range of lambda values and its results,using this we can choose appropriate values\n",
    "# 2.random search cv -we can use random search cv for range of values for particular iteration and particual solver,so it will be more efficient than grid search cv\n",
    "# 3.cross validation\n",
    "# 4.domain experts\n",
    "# 5.automatic vallue detection by scikit-learn kind of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91f0fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f2c7052",
   "metadata": {},
   "source": [
    "# Q4. Can Ridge Regression be used for feature selection? If yes, how"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d50695",
   "metadata": {},
   "source": [
    "## yes,In ridge regression the coefficient of features which has less relationship with output  will be equal to zero.so,thats the form of feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de9930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec670414",
   "metadata": {},
   "source": [
    "# Q5. How does the Ridge Regression model perform in the presence of multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f295c7",
   "metadata": {},
   "source": [
    "# Suppose you're building a linear regression model to predict house prices, and you have two highly correlated features: \"Square Footage\" and \"Number of Bedrooms.\" Multicollinearity arises because larger houses tend to have more bedrooms, and vice versa. Here's how Ridge Regression can help in this scenario:\n",
    "\n",
    "1. **Standard Linear Regression**: Without regularization, standard linear regression might struggle with multicollinearity. It could assign high coefficients to both \"Square Footage\" and \"Number of Bedrooms,\" making the model sensitive to small changes in these features.\n",
    "\n",
    "2. **Ridge Regression**: By applying Ridge Regression, you introduce a regularization term. The Ridge penalty term will shrink the coefficients of \"Square Footage\" and \"Number of Bedrooms\" towards zero. The coefficients may not be eliminated entirely, but they will be reduced. This means that your model becomes less dependent on these correlated features.\n",
    "\n",
    "Let's see the coefficients of the two features in both models:\n",
    "\n",
    "**Standard Linear Regression:**\n",
    "- Square Footage coefficient: 100,000\n",
    "- Number of Bedrooms coefficient: 50,000\n",
    "\n",
    "**Ridge Regression:**\n",
    "- Square Footage coefficient (after regularization): 80,000\n",
    "- Number of Bedrooms coefficient (after regularization): 40,000\n",
    "\n",
    "In this example, Ridge Regression has effectively reduced the impact of multicollinearity by shrinking the coefficients. The coefficients are still positive, indicating that both features have some importance, but their magnitudes are smaller, making the model more stable and better at generalizing to new data. Ridge Regression strikes a balance between retaining valuable information from both features while mitigating the problems associated with multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d258c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f77e61b",
   "metadata": {},
   "source": [
    "# Q6. Can Ridge Regression handle both categorical and continuous independent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed4f61a",
   "metadata": {},
   "source": [
    "# yes can handle both continuous and categorical ,but we need to some encoding process for categorical values ex.one hot encoding,label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d73b885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84bc92b8",
   "metadata": {},
   "source": [
    "# Q7. How do you interpret the coefficients of Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ab3198",
   "metadata": {},
   "source": [
    "## interpreting Ridge Regression coefficients involves considering their magnitude, sign, stability, and relative importance. Ridge Regression is useful for reducing the impact of multicollinearity and stabilizing coefficient estimates, but it's important to keep in mind that the coefficients are influenced by the regularization term, which aims to strike a balance between bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da297be",
   "metadata": {},
   "source": [
    "# Q8. Can Ridge Regression be used for time-series data analysis? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ff78fe",
   "metadata": {},
   "source": [
    "# , Ridge Regression can be adapted for time-series data analysis by incorporating relevant temporal features, ensuring stationarity, selecting an appropriate regularization parameter, and using rolling Ridge Regression to make predictions into the future. Keep in mind that time-series analysis often involves unique challenges, such as autocorrelation and seasonality, which may require additional modeling techniques or adjustments to address effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f83791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a387b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e960c2cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c209b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3b5acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

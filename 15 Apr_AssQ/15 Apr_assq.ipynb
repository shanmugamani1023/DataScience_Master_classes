{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Data Science Masters\n",
    "\n",
    "\n",
    "Note:  Create your assignment in Jupyter notebook and upload it to GitHub & share that github repository \n",
    "           link through your dashboard. Make sure the repository is public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. You are working on a machine learning project where you have a dataset containing numerical and categorical features. You have identified that some of the features are highly correlated and there are missing values in some of the columns. You want to build a pipeline that automates the feature engineering process and handles the missing values. \n",
    "Design a pipeline that includes the following steps\"\n",
    " Use an automated feature selection method to identify the important features in the datasetC\n",
    " Create a numerical pipeline that includes the following steps\"\n",
    " Impute the missing values in the numerical columns using the mean of the column valuesC\n",
    " Scale the numerical columns using standardisationC\n",
    " Create a categorical pipeline that includes the following steps\"\n",
    " Impute the missing values in the categorical columns using the most frequent value of the columnC\n",
    " One-hot encode the categorical columns\n",
    " Combine the numerical and categorical pipelines using a ColumnTransformerC\n",
    " Use a Random Forest Classifier to build the final modelC\n",
    " Evaluate the accuracy of the model on the test dataset. \n",
    "Note: Your solution should include code snippets for each step of the pipeline, and a brief explanation of each step. You should also provide an interpretation of the results and suggest possible improvements for the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Automated feature selection\n",
    "feature_selection_model = RandomForestClassifier()  # You can use any model for feature selection\n",
    "feature_selector = SelectFromModel(feature_selection_model)\n",
    "\n",
    "# Step 2: Numerical pipeline\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values using mean\n",
    "    ('scaler', StandardScaler())  # Scale numerical columns using standardization\n",
    "])\n",
    "\n",
    "# Step 3: Categorical pipeline\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values using most frequent value\n",
    "    ('encoder', OneHotEncoder())  # One-hot encode categorical columns\n",
    "])\n",
    "\n",
    "# Step 4: Combine numerical and categorical pipelines\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numeric', numerical_pipeline, numerical_features),  # numerical_features contains the numerical column names\n",
    "    ('categorical', categorical_pipeline, categorical_features)  # categorical_features contains the categorical column names\n",
    "])\n",
    "\n",
    "# Step 5: Build the final model pipeline\n",
    "final_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier())  # You can adjust the hyperparameters of RandomForestClassifier\n",
    "])\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "final_pipeline.fit(X_train, y_train)  # Assuming X_train and y_train are your training data\n",
    "y_pred = final_pipeline.predict(X_test)  # Assuming X_test is your test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a pipeline with Random Forest and Logistic Regression classifiers\n",
    "rf_pipeline = Pipeline([\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "lr_pipeline = Pipeline([\n",
    "    ('lr', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Combine the individual pipelines into a Voting Classifier\n",
    "voting_pipeline = VotingClassifier(estimators=[\n",
    "    ('rf', rf_pipeline),\n",
    "    ('lr', lr_pipeline)\n",
    "], voting='hard')  # 'hard' voting combines the predicted class labels\n",
    "\n",
    "# Train the voting classifier on the training data\n",
    "voting_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy of the voting classifier on the test data\n",
    "accuracy = accuracy_score(y_test, voting_pipeline.predict(X_test))\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pwskills",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
